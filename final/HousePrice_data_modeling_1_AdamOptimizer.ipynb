{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price: Advanced regression technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep learning modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = All features\n",
    "tf.set_random_seed(123)\n",
    "house = pd.read_csv(\"./data/HousePrice_preprocessing_full_ver5.csv\")\n",
    "filename_queue = tf.train.string_input_producer(['./data/HousePrice_preprocessing_full_ver6.csv'],\n",
    "                                                shuffle=False, name='filename_queue')\n",
    "key, value = tf.TextLineReader().read(filename_queue)\n",
    "record_defaults = list(np.zeros((69,1))) # 69ì¹¸\n",
    "xy = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "\n",
    "# collect batches of csv in\n",
    "train_x_batch, train_y_batch = tf.train.batch([xy[1:-1], xy[-1:]], batch_size=10)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 67])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "W = tf.Variable(tf.random_normal([67,1], name = 'weight'))\n",
    "b = tf.Variable(tf.random_normal([1], name='bias'))\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "# accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001  | cost = 27599494943.561641693\n",
      "Epoch: 0002  | cost = 12882935702.794519424\n",
      "Epoch: 0003  | cost = 7289446950.575342178\n",
      "Epoch: 0004  | cost = 5677706313.643836975\n",
      "Epoch: 0005  | cost = 5289362905.424657822\n",
      "Epoch: 0006  | cost = 5165598832.219181061\n",
      "Epoch: 0007  | cost = 5086027960.109589577\n",
      "Epoch: 0008  | cost = 5016200263.890409470\n",
      "Epoch: 0009  | cost = 4952271526.575342178\n",
      "Epoch: 0010  | cost = 4893763036.931503296\n",
      "Epoch: 0011  | cost = 4840329596.493150711\n",
      "Epoch: 0012  | cost = 4791515830.356163025\n",
      "Epoch: 0013  | cost = 4746793461.479450226\n",
      "Epoch: 0014  | cost = 4705609806.904109955\n",
      "Epoch: 0015  | cost = 4667427463.013697624\n",
      "Epoch: 0016  | cost = 4631748385.315068245\n",
      "Epoch: 0017  | cost = 4598129614.904109001\n",
      "Epoch: 0018  | cost = 4566188836.821918488\n",
      "Epoch: 0019  | cost = 4535604769.315066338\n",
      "Epoch: 0020  | cost = 4506113921.753426552\n",
      "Epoch: 0021  | cost = 4477505001.205478668\n",
      "Epoch: 0022  | cost = 4449612200.328767776\n",
      "Epoch: 0023  | cost = 4422307548.931508064\n",
      "Epoch: 0024  | cost = 4395494194.849314690\n",
      "Epoch: 0025  | cost = 4369101461.041095734\n",
      "Epoch: 0026  | cost = 4343077523.287670135\n",
      "Epoch: 0027  | cost = 4317386348.712328911\n",
      "Epoch: 0028  | cost = 4292002787.945206642\n",
      "Epoch: 0029  | cost = 4266910804.164385796\n",
      "Epoch: 0030  | cost = 4242099747.068491459\n",
      "Epoch: 0031  | cost = 4217563330.630136967\n",
      "Epoch: 0032  | cost = 4193297460.602739334\n",
      "Epoch: 0033  | cost = 4169300806.136985779\n",
      "Epoch: 0034  | cost = 4145572302.904108047\n",
      "Epoch: 0035  | cost = 4122110914.630136490\n",
      "Epoch: 0036  | cost = 4098916439.671231747\n",
      "Epoch: 0037  | cost = 4075987980.273972034\n",
      "Epoch: 0038  | cost = 4053323977.643836498\n",
      "Epoch: 0039  | cost = 4030923407.780821323\n",
      "Epoch: 0040  | cost = 4008783654.575341702\n",
      "Epoch: 0041  | cost = 3986902201.863013744\n",
      "Epoch: 0042  | cost = 3965276158.246575356\n",
      "Epoch: 0043  | cost = 3943901881.863013744\n",
      "Epoch: 0044  | cost = 3922775671.232878685\n",
      "Epoch: 0045  | cost = 3901893337.424657345\n",
      "Epoch: 0046  | cost = 3881250419.726028442\n",
      "Epoch: 0047  | cost = 3860842520.547944546\n",
      "Epoch: 0048  | cost = 3840664881.095889568\n",
      "Epoch: 0049  | cost = 3820712549.698630810\n",
      "Epoch: 0050  | cost = 3800980039.890410900\n",
      "Epoch: 0051  | cost = 3781463459.068492413\n",
      "Epoch: 0052  | cost = 3762156956.054794312\n",
      "Epoch: 0053  | cost = 3743056247.232878208\n",
      "Epoch: 0054  | cost = 3724155828.602740288\n",
      "Epoch: 0055  | cost = 3705451609.424655914\n",
      "Epoch: 0056  | cost = 3686938285.589041233\n",
      "Epoch: 0057  | cost = 3668611824.219178200\n",
      "Epoch: 0058  | cost = 3650467345.534246445\n",
      "Epoch: 0059  | cost = 3632500864.000001431\n",
      "Epoch: 0060  | cost = 3614708192.438356400\n",
      "Epoch: 0061  | cost = 3597085250.630136013\n",
      "Epoch: 0062  | cost = 3579628138.958903790\n",
      "Epoch: 0063  | cost = 3562332987.616437912\n",
      "Epoch: 0064  | cost = 3545196710.575343609\n",
      "Epoch: 0065  | cost = 3528215409.972602844\n",
      "Epoch: 0066  | cost = 3511386287.342464447\n",
      "Epoch: 0067  | cost = 3494705863.890410423\n",
      "Epoch: 0068  | cost = 3478171444.602737904\n",
      "Epoch: 0069  | cost = 3461779862.794520855\n",
      "Epoch: 0070  | cost = 3445528563.726027966\n",
      "Epoch: 0071  | cost = 3429415367.890410423\n",
      "Epoch: 0072  | cost = 3413437562.739725590\n",
      "Epoch: 0073  | cost = 3397592817.972602367\n",
      "Epoch: 0074  | cost = 3381878969.863014221\n",
      "Epoch: 0075  | cost = 3366293663.561641693\n",
      "Epoch: 0076  | cost = 3350835181.589040756\n",
      "Epoch: 0077  | cost = 3335501530.301369667\n",
      "Epoch: 0078  | cost = 3320290928.219178200\n",
      "Epoch: 0079  | cost = 3305201670.136985302\n",
      "Epoch: 0080  | cost = 3290231815.013698101\n",
      "Epoch: 0081  | cost = 3275380249.424656868\n",
      "Epoch: 0082  | cost = 3260645205.917809010\n",
      "Epoch: 0083  | cost = 3246025231.780822277\n",
      "Epoch: 0084  | cost = 3231518879.561645985\n",
      "Epoch: 0085  | cost = 3217125361.972603321\n",
      "Epoch: 0086  | cost = 3202842605.589042187\n",
      "Epoch: 0087  | cost = 3188669907.287671089\n",
      "Epoch: 0088  | cost = 3174605980.931504250\n",
      "Epoch: 0089  | cost = 3160649731.506849766\n",
      "Epoch: 0090  | cost = 3146799898.301370144\n",
      "Epoch: 0091  | cost = 3133055715.068493843\n",
      "Epoch: 0092  | cost = 3119415944.767123222\n",
      "Epoch: 0093  | cost = 3105879774.684931755\n",
      "Epoch: 0094  | cost = 3092446171.178081512\n",
      "Epoch: 0095  | cost = 3079114494.246575832\n",
      "Epoch: 0096  | cost = 3065883576.986301422\n",
      "Epoch: 0097  | cost = 3052752406.794520378\n",
      "Epoch: 0098  | cost = 3039720523.397260189\n",
      "Epoch: 0099  | cost = 3026786767.780822277\n",
      "Epoch: 0100  | cost = 3013950614.794520855\n",
      "Epoch: 0101  | cost = 3001210982.575341225\n",
      "Epoch: 0102  | cost = 2988567550.246574402\n",
      "Epoch: 0103  | cost = 2976019198.246574879\n",
      "Epoch: 0104  | cost = 2963565415.452054501\n",
      "Epoch: 0105  | cost = 2951205523.287671089\n",
      "Epoch: 0106  | cost = 2938938215.452055454\n",
      "Epoch: 0107  | cost = 2926763580.493150234\n",
      "Epoch: 0108  | cost = 2914680594.410960197\n",
      "Epoch: 0109  | cost = 2902688466.410959721\n",
      "Epoch: 0110  | cost = 2890786974.684930801\n",
      "Epoch: 0111  | cost = 2878975093.479451656\n",
      "Epoch: 0112  | cost = 2867252267.835616589\n",
      "Epoch: 0113  | cost = 2855617611.397260189\n",
      "Epoch: 0114  | cost = 2844071020.712328911\n",
      "Epoch: 0115  | cost = 2832611644.493150234\n",
      "Epoch: 0116  | cost = 2821238719.999999523\n",
      "Epoch: 0117  | cost = 2809951760.657533646\n",
      "Epoch: 0118  | cost = 2798750162.410958290\n",
      "Epoch: 0119  | cost = 2787633333.479451180\n",
      "Epoch: 0120  | cost = 2776600861.808219433\n",
      "Epoch: 0121  | cost = 2765651788.273972511\n",
      "Epoch: 0122  | cost = 2754785833.205478668\n",
      "Epoch: 0123  | cost = 2744002374.136986732\n",
      "Epoch: 0124  | cost = 2733301027.945205688\n",
      "Epoch: 0125  | cost = 2722680772.383561134\n",
      "Epoch: 0126  | cost = 2712141425.095891476\n",
      "Epoch: 0127  | cost = 2701682037.479452610\n",
      "Epoch: 0128  | cost = 2691302394.739724636\n",
      "Epoch: 0129  | cost = 2681001826.191780090\n",
      "Epoch: 0130  | cost = 2670779669.917808533\n",
      "Epoch: 0131  | cost = 2660635821.589041710\n",
      "Epoch: 0132  | cost = 2650569272.109589100\n",
      "Epoch: 0133  | cost = 2640579663.780821323\n",
      "Epoch: 0134  | cost = 2630666446.027397156\n",
      "Epoch: 0135  | cost = 2620829050.739726067\n",
      "Epoch: 0136  | cost = 2611066963.287671566\n",
      "Epoch: 0137  | cost = 2601379771.616438389\n",
      "Epoch: 0138  | cost = 2591766862.027397633\n",
      "Epoch: 0139  | cost = 2582227832.986300468\n",
      "Epoch: 0140  | cost = 2572761933.150684834\n",
      "Epoch: 0141  | cost = 2563368797.808218002\n",
      "Epoch: 0142  | cost = 2554047929.863013268\n",
      "Epoch: 0143  | cost = 2544798676.164382935\n",
      "Epoch: 0144  | cost = 2535620863.123287678\n",
      "Epoch: 0145  | cost = 2526513578.958903790\n",
      "Epoch: 0146  | cost = 2517476425.643835068\n",
      "Epoch: 0147  | cost = 2508509052.493151188\n",
      "Epoch: 0148  | cost = 2499610901.917808533\n",
      "Epoch: 0149  | cost = 2490781470.684931278\n",
      "Epoch: 0150  | cost = 2482020199.452055454\n",
      "Epoch: 0151  | cost = 2473326758.575343132\n",
      "Epoch: 0152  | cost = 2464700458.082191944\n",
      "Epoch: 0153  | cost = 2456140927.123288155\n",
      "Epoch: 0154  | cost = 2447647662.465754032\n",
      "Epoch: 0155  | cost = 2439220363.397260189\n",
      "Epoch: 0156  | cost = 2430858291.726027966\n",
      "Epoch: 0157  | cost = 2422561054.684932232\n",
      "Epoch: 0158  | cost = 2414328162.191781044\n",
      "Epoch: 0159  | cost = 2406159167.123287201\n",
      "Epoch: 0160  | cost = 2398053660.931506634\n",
      "Epoch: 0161  | cost = 2390010993.095890045\n",
      "Epoch: 0162  | cost = 2382030751.561643600\n",
      "Epoch: 0163  | cost = 2374112791.671232700\n",
      "Epoch: 0164  | cost = 2366256284.054794312\n",
      "Epoch: 0165  | cost = 2358460913.095890522\n",
      "Epoch: 0166  | cost = 2350726172.054793835\n",
      "Epoch: 0167  | cost = 2343051621.698629856\n",
      "Epoch: 0168  | cost = 2335436868.383561134\n",
      "Epoch: 0169  | cost = 2327881212.493150711\n",
      "Epoch: 0170  | cost = 2320384611.068492889\n",
      "Epoch: 0171  | cost = 2312946175.123288155\n",
      "Epoch: 0172  | cost = 2305566040.547945023\n",
      "Epoch: 0173  | cost = 2298243226.301369190\n",
      "Epoch: 0174  | cost = 2290977591.232876778\n",
      "Epoch: 0175  | cost = 2283768622.465754032\n",
      "Epoch: 0176  | cost = 2276615877.260274410\n",
      "Epoch: 0177  | cost = 2269518793.643835545\n",
      "Epoch: 0178  | cost = 2262477296.219178200\n",
      "Epoch: 0179  | cost = 2255490771.287671566\n",
      "Epoch: 0180  | cost = 2248558710.356164932\n",
      "Epoch: 0181  | cost = 2241680592.657533646\n",
      "Epoch: 0182  | cost = 2234856391.013698578\n",
      "Epoch: 0183  | cost = 2228085339.178081989\n",
      "Epoch: 0184  | cost = 2221367289.863014221\n",
      "Epoch: 0185  | cost = 2214701751.232876301\n",
      "Epoch: 0186  | cost = 2208087928.986300468\n",
      "Epoch: 0187  | cost = 2201525987.945205688\n",
      "Epoch: 0188  | cost = 2195015253.041095734\n",
      "Epoch: 0189  | cost = 2188555562.082191944\n",
      "Epoch: 0190  | cost = 2182145993.643836021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0191  | cost = 2175786716.054795265\n",
      "Epoch: 0192  | cost = 2169476978.849314213\n",
      "Epoch: 0193  | cost = 2163216355.068493366\n",
      "Epoch: 0194  | cost = 2157004727.232876301\n",
      "Epoch: 0195  | cost = 2150841647.342465878\n",
      "Epoch: 0196  | cost = 2144726527.123287916\n",
      "Epoch: 0197  | cost = 2138659313.095890522\n",
      "Epoch: 0198  | cost = 2132639312.657533884\n",
      "Epoch: 0199  | cost = 2126666243.506848812\n",
      "Epoch: 0200  | cost = 2120739800.547945738\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "training_epochs = 200\n",
    "batch_size = 20\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(len(house) / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs = house.iloc[i*batch_size:(i+1)*batch_size, 1:-1]\n",
    "        batch_ys = house.iloc[i*batch_size:(i+1)*batch_size, -1:]\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, train], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), ' | cost =', '{:.9f}'.format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={X: batch_xs, Y: batch_ys}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "? tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
